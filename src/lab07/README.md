## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ7
### –ó–∞–¥–∞–Ω–∏–µ A
```py
import pytest #–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π

from src.lib.text import count_freq, normalize, tokenize, top_n

#–ø–∞—Ä–∞–º–∞—Ç—Ä–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ (—á—Ç–æ –ø–æ–¥–∞–µ—Ç—Å—è, —á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å—Å—è), –¥–∞–ª–µ–µ - —Å–∞–º —Ç–µ—Å—Ç
@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize(src, expected):
    assert normalize(src) == expected

@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize(src, expected):
    assert tokenize(src) == expected


@pytest.mark.parametrize(
        "tokens, expected",
        [
            (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}), 
            (["good","good","good"], {"good":3}), #–ø—Ä–æ–≤–µ—Ä–∫–∞, –∫–æ–≥–¥–∞ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
            (["üíï","üíï","üíï","ü§∑‚Äç‚ôÄÔ∏è"],{"üíï":3,"ü§∑‚Äç‚ôÄÔ∏è":1}), #–ø—Ä–æ–≤–µ—Ä–∫–∞ —ç–º–æ–¥–∑–∏
        ],
)
def test_count_freq(tokens, expected):
    assert count_freq(tokens) == expected

@pytest.mark.parametrize(
        "words, n, expected",
        [
        ({"c":6, "a":6, "b":2}, 2, [("a", 6), ("c", 6)]), #–∫–æ–≥–¥–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∫–æ–ª-–≤–æ -> –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        ({"a": 3, "b": 2}, 5, [("a", 3), ("b", 2)]), #n –±–æ–ª—å—à–µ —á–µ–º –≤—Å–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π
        ],
)

def test_top_n(words, n, expected):
    assert top_n(words, n) == expected

#–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ—Ç—É
def test_empty():
    assert normalize("") == ""
    assert tokenize("") == []
    assert count_freq([]) == {}
    assert top_n({}, 5) == []
``` 

### –ó–∞–¥–∞–Ω–∏–µ B
```py
import json, csv
from pathlib import Path
import pytest
from lab05.json_csv import json_to_csv
from lab05.csv_json import csv_to_json

##–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
#–∑–∞–ø–∏—Å—å –æ–±—ä–µ–∫—Ç–∞ –≤ json —Ñ–∞–π–ª
def write_json(path: Path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

#—á–∏—Ç–∞–µ—Ç csv –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –≥–¥–µ –∫–ª—é—á–∏ - –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
def read_csv_rows(path: Path):
    with path.open(encoding="utf-8") as f:
        return list(csv.DictReader(f))

def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json" #—Å–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    dst = tmp_path / "people.csv"
    data = [{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}]
    write_json(src, data) #–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ

    json_to_csv(str(src), str(dst)) #—Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é
    rows = read_csv_rows(dst) —á—Ç–µ–Ω–∏–µ —Ä–µ–∑-—Ç–∞
    assert len(rows) == 2
    assert set(rows[0]) >= {"name", "age"} #–ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –∫–∞–∫ –º–∏–Ω–∏–º—É–º —ç—Ç–∏ –¥–≤–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–º–µ—é—Ç—Å—è


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv" #—Å–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π csv; –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    dst = tmp_path / "people.json"
    src.write_text("name,age\nAlice,22\nBob,25\n", encoding="utf-8")#–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ü—Å–≤ –¥–∞–Ω–Ω—ã–µ

    csv_to_json(str(src), str(dst)) #—Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ñ-—Ü–∏—é
    obj = json.loads(dst.read_text(encoding="utf-8")) #—á–∏—Ç–∞–µ–º json (–∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ –æ–±—ä–µ–∫—Ç)
    assert isinstance(obj, list) and len(obj) == 2
    assert set(obj[0]) == {"name", "age"}

#—Ç–µ—Å—Ç –ø—É—Å—Ç–æ–≥–æ json
def test_json_to_csv_empty_raises(tmp_path: Path):
    src = tmp_path / "empty.json"
    src.write_text("[]", encoding="utf-8") #—Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
    with pytest.raises(ValueError): #–≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –æ—à–∏–±–∫–∞
        json_to_csv(str(src), str(tmp_path / "out.csv"))

#—Ç–µ—Å—Ç csv –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
def test_csv_to_json_no_header_raises(tmp_path: Path):
    src = tmp_path / "bad.csv"
    src.write_text("", encoding="utf-8") #–ø–∏—à–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
    with pytest.raises(ValueError): #–≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –æ—à–∏–±–∫–∞
        csv_to_json(str(src), str(tmp_path / "out.json"))

#—Ç–µ—Å—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
def test_missing_file_raises():
    with pytest.raises(FileNotFoundError): #–≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –æ—à–∏–±–∫–∞
        csv_to_json("nope.csv", "out.json")
```
## —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã 
### pytest:
![alt text](../../images/lab07/test.png)

### black :
![alt text](../../images/lab07/blackk.png)